\section{Evaluation and results}
\label{sec:results}
We now discuss the results we obtained by applying our techniques on our
datasets, nine years worth of archived data.  We begin by presenting the results
of the churn rate analysis, followed by the uptime analysis, and the fingerprint
analysis.  Next, we characterize the most interesting Sybils we found in our
analysis.  Finally, we evaluate our nearest-neighbor search and the
computational performance of all our analysis techniques.

Once we discovered a seemingly harmful Sybil group, we reported it to The Tor
Project.  There are currently two ways for directory authorities to remove
relays, controlled by the options \texttt{AuthDirReject} and
\texttt{AuthDirInvalid}.  The former removes a relay from the consensus and the
latter takes away a relay's \texttt{Valid} flag.  While the relay is still
listed in the consensus, clients will not consider it for their first or last
hop in a circuit.

The majority of directory authorities, i.e., five out of eight, must agree on
either \texttt{AuthDirReject} or \texttt{AuthDirInvalid} to be set for a relay.
Only then will the block become active.  This mechanism is meant to distribute
the power of removing relays into the hands of a diverse set of people.

\subsection{Sybil characterization}
\label{sec:sybil_groups}
Table~\ref{tab:sybils} contains the Sybil groups we identified using our
sybilhunter heuristics and our custom exitmap modules.  For every group, we
document when we first discovered it, its ``name,'' maximal size, and a
description of its purpose.  We now give an overview of the more interesting
groups we exposed.

\begin{table*}[t]
\small
\centering
\begin{tabularx}{\textwidth}{c|c c c c X}
\textbf{Purpose} & \textbf{First active} & \textbf{Group ID} & \textbf{\# of
relays} & \textbf{Heuristic} & \textbf{Description} \\
\hline
%2015-11-28 & foo & 60 & not sure. \\

\multirow{6}{*}{MitM}
& 2015-11 & rewrite$\dagger$ & 8 & EM & Replaced onion domains with impersonation
site. \\

& 2015-06 & rewrite$\dagger$ & 55 & EM & Replaced onion domains with impersonation
site. \\

& 2015-04 & rewrite$\dagger$ & 70 & EM & Replaced onion domains with impersonation
site. \\

& 2015-03 & redirect$\ddagger$ & 24 & EM & Redirected users to impersonated site.
\\

& 2015-02 & redirect$\ddagger$ & 17 & EM & Redirected users to impersonated site.
\\

& 2015-01 & redirect$\ddagger$ & 23 & EM & Redirected users to impersonated site.
\\

\hline

\multirow{3}{*}{DHT}
& 2015-06 & fingerprints & 28 & FPR & All relays, located in the same /24, changed
their fingerprint regularly, presumably in an attempt to manipulate the
distributed hash table. \\

& 2014-01 & FDCservers & 126 & UP & Relays that were involved in an onion service
deanonymization attack~\cite{cmucert}. \\

\hline

\multirow{2}{*}{Botnet}
& 2015-08 & default & --- & F & Likely a Windows-powered botnet.  The group features
wide, geographical distribution, which is uncommon for typical Tor relays. \\

& 2010-09 & trotsky & 219 & F & The relays could have been part of a botnet. \\

\hline

\multirow{5}{*}{Unknown}
& 2015-10 & 11BX1371 & 142 & F & All relays were in two /24 networks and a single
relay had the \texttt{Exit} flag.  \\

& 2015-07 & DenkoNet & 58 & F & Hosted on Amazon AWS and only present in a single
consensus.  No relay had the \texttt{Exit} flag. \\

& 2015-07 & cloudvps & 55 & F & All relays only had the \texttt{Running} and
\texttt{Valid} flag.  As their name suggests, the relays were hosted by the
Dutch hoster ``CloudVPS.'' \\

% Shared: nickname, IP address, port, platform, version.
& 2014-12 & Anonpoke & 284 & F & The relays did not have the \texttt{Exit} flag
and were removed from the network before they could get the \texttt{HSDir} flag.
\\

& 2014-12 & FuslVZTOR & 246 & F & The relays showed up only hours after the
LizardNSA incident. \\

\hline

\multirow{1}{*}{DoS}
& 2014-12 & LizardNSA & 3,347 & UP,CRN & A group publicly claimed to be responsible
for the attack~\cite{lizards}.  All relays were hosted in the Google cloud and
The Tor Project removed them within hours. \\

\hline

\multirow{2}{*}{Research}
& 2010-06 & planetlab & 512 & UP & According to a report from The Tor
Project~\cite{progressreport}, a researcher started these relays to learn more
about scalability effects. \\

& 2013-02 & AmazonEC2 & 57 & FPR & The relays were likely part of a research
project~\cite{Biryukov2013a}. \\

\end{tabularx}
\caption{The Sybil groups we discovered using sybilhunter and our custom exitmap
modules, grouped by their purpose.  We believe that groups marked with the
symbols $\dagger$ and $\ddagger$ were run by the same operator, respectively.}
\label{tab:sybils}
\end{table*}

\paragraph{The ``rewrite'' Sybils}
All relays had the \texttt{Exit} flag and replaced onion domains in HTTP page
fetches with an impersonation, presumably hosted by the attacker.
Interestingly, the impersonation domains shared a prefix with the original,
e.g., \textbf{sigaint}evyh2rzvw.onion was replaced with
\textbf{sigaint}z7qjj3val.onion.  The shared prefix means that the attacker was
generating vanity domains by repeatedly generating public key pairs until the
hash over the key resembled the desired prefix.  Onion domains are generated by
determining the SHA-1 hash over the public key, truncating it to the 80 most
significant bits, and encoding it in Base32.  Each Base32 digit of the
16-digit-domain represents five bits.  As a result, to get an $n$-digit prefix
in the onion domain, $2^{5 n - 1}$ operations are required on average.  For the
seven-digit prefix above, this results in $2^{5 \cdot 7 - 1} = 2^{34}$
operations.  The author of scallion~\cite{scallion}, a tool for generating
vanity onion domains, determined that an nVidia Quadro K2000M, a mid-range
laptop GPU, is able to generate 90 million hashes per second.  On this GPU, a
partial collision for a seven-digit prefix can be found in $2^{34} \cdot
\frac{1}{90,000,000} \simeq 190$ seconds, i.e., in a little bit more than three
minutes.

We found that attacked onion domains contained Bitcoin wallet addresses that
were replaced in the impersonation, presumably to hijack donations or payments.
As a result, we believe that the attack was financially motivated.

\paragraph{The ``redirect'' Sybils}
The relays all had the \texttt{Exit} flag and tampered with HTTP redirects of
exit traffic.  Some Bitcoin sites would redirect users from their HTTP version
to the secure HTTPS version, to protect their users' login credentials.  This
Sybil group, however, tampered with the redirect and directed users towards an
impersonation site, resembling the original Bitcoin site, perhaps to steal
credentials.  We only observed this attack for Bitcoin sites, but cannot rule
out that other sites were not attacked.

Interestingly, the Sybils' server descriptors and consensus entries had less in
common than other Sybil groups.  They used a small set of different ports, Tor
versions, bandwidth values, and their nicknames did not exhibit an
easily-recognizable pattern.  In fact, we can only clearly identify these Sybils
because of the active attack they run, using exitmap, and not because of their
appearance.

We discovered three Sybil groups that implemented the redirect attack, each of
them surfacing when the previous one got blocked.  The first group first showed
up in May 2014, with only two relays, but slowly grew over time, until it was
finally discovered in Jan 2015.  We believe that they were run by the same
attacker because of the way the attack was implemented.

\paragraph{The ``default'' Sybils}
This Sybil group, named after the shared nickname ``default,'' has been around
since 2011 (see Figure~\ref{fig:default-over-time}) and consists of
Windows-powered relays only.  We extracted relays by filtering consensuses
for nicknames that are set to ``default,'' onion routing ports set to 443, and
directory ports set to 9030.  The group features high IP address churn.  For
Oct. 2015, we found ``default'' relays in 73 countries, with the top three
countries being Germany~(50\%), Russia~(8\%), and Austria~(7\%).  The majority
of these relays, however, has little uptime.
Figure~\ref{fig:default-sybils-uptime} shows the uptime matrix for ``default''
relays in Oct. 2015.  Many relays exhibit a diurnal pattern, suggesting
that they are powered off regularly---as it often is the case for desktop PCs.

\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{diagrams/default-over-time}
	\caption{The number of members of the ``default'' Sybil group over time.
		The relays surfaced in Sep 2011 and occasionally amounted to several
		hundred members online at the same time.}
	\label{fig:default-over-time}
\end{figure}

To get a better understanding of the number of ``default'' relays over time, we
analyzed all consensuses, extracting the number of relays whose nickname was
``default,'' whose onion routing port was 443, and whose directory port was
9001.  We did this for the first consensus every day and plot the result in
Figure~\ref{fig:default-over-time}.

The above suggests that some of these relays are running without the owner's
knowledge.  The relays do not fit the pattern of Sefnit (a.k.a.
Mevade)~\cite{sefnit} and Skynet~\cite{skynet}, two pieces of malware that use
an onion service as command and control server.  Nevertheless, we believe that
these are part of a botnet.

\paragraph{The ``trotsky'' Sybils}
Similar to the ``default'' group, the ``trotsky'' relays appear to be part of
a botnet.  Most of the relays' IP addresses were located in Eastern Europe, in
particular in Slovenia, Croatia, and Bosnia and Herzegovina.  The relays were
all running on Windows, in version 0.2.1.26, and listening on port 443.  Most of
the relays were configured as exits, and The Tor Project assigned some of them
the \texttt{BadExit} flag.

The first relays started appearing in Sep 2010.  Over time, there were two relay
peaks, reaching 139 (Sep 23) and 219 (Oct 3) relays.  After that, only 1--3
relays remained in the consensus.

\paragraph{The ``Amazon EC2'' Sybils}
The relays all used randomly-generated nicknames, consisting of 16 letters and
numbers; Tor in version 0.2.2.37; GNU/Linux; and IP addresses in Amazon's
netblock.  Every IP address changed its fingerprint 24 times, but not randomly:
the fingerprints were chosen systematically, in a small range.  For example,
relay 54.242.248.129 used fingerprints starting with the prefixes \texttt{8D},
\texttt{8E}, \texttt{8F}, and \texttt{90}.  The relays were online for 48 hours.
After 24 hours, most of the relays obtained the \texttt{HSDir} flag.

We believe that this Sybil group was run by Biryukov, Pustogarov, and Weinmann
for their paper ``Trawling for Tor Hidden Services''~\cite{Biryukov2013a}.

\paragraph{The ``LizardNSA'' Sybils}
All relays were hosted in the Google Cloud, and only online for nine hours,
until the directory authorities started rejecting them.  The majority of
machines were middle relays (96\%), but the attackers also started some exit
relays (4\%).  The Sybils were set up to be onion service directories, but the
relays were taken offline before they were assigned the \texttt{HSDir} flag.  If
all relays would have obtained the \texttt{HSDir} flag in time, they would have
constituted almost 50\% of all onion service directories; the median number of
onion service directories on Dec. 26 was 3,551.

\paragraph{The ``FuslVZTOR'' Sybils}
All machines were middle relays and hosted in 212.38.181.0/24, a VPS provider's
network in the UK.  The directory authorities started rejecting the relays five
hours after they were first seen.  The relays advertized the default bandwidth
of 1 GiB/s and used seemingly randomly determined ports.  Other than happening
in parallel to the LizardNSA attack, there is no reason to believe that both
incidents are related.

\paragraph{The ``Anonpoke'' Sybils}
All relays shared the nickname ``Anonpoke'' and were online for four hours until
they were rejected.  All relays were hosted by a VPS provider in the US,
Rackspace, with the curious exception of a single relay that was hosted in the
UK, and running a different Tor version.  The relays advertized the default
bandwidth of 1 GiB/s on port 9001 and 9030.  All relays were middle relays and
running as directory mirror.  All Sybils were configured to be an onion service
directory, but did not manage to get the flag in time.

\paragraph{The ``PlanetLab'' Sybils}
A set of relays that used a variation of the strings ``planet'', ``plab'',
``pl'', and ``planetlab'' as their nickname.  The relays' exit policy allowed
ports 6660--6667, but they did not get the \texttt{Exit} flag.  The Sybils were
online for three days and then removed by The Tor Project, as mentioned in a
blog post~\cite{progressreport}.  The blog post further says that the relays
were run by a researcher.

\paragraph{The ``FDCservers'' Sybils}
These Sybils were used to deanonymize onion service users, as discussed by The
Tor Project in a July 2014 blog post~\cite{cmucert}.  Supposedly, a research
institute was executing a traffic confirmation attack by sending sequences of
\texttt{RELAY\_EARLY} and \texttt{RELAY} cells as a signal down the circuit to
the client, which the reference implementation never does.  The attacking relays
were onion service directories and guards, allowing them to control both ends of
the circuit for some Tor clients that were fetching onion service descriptors.
All relays were running FreeBSD, used Tor in version 0.2.4.18-rc, had identical
flags, mostly identical bandwidth values, and were located in 50.7.0.0/16 and
204.45.0.0/16.  All of these shared configuration options made the relays easy
to identify.

The relays were added to the network in batches, starting on Dec 10, 2013 with
29 relays.  On Jan 30, 2014, the attackers added 58 relays to the 63 existing
ones, giving them control over 121 relays.  On Jul 8, 2014, The Tor Project
blocked all 126 relays that were running at the time.

% \subsubsection{Bitcoin}
% The ones that are stealing bitcoins.
% 
% Look at blockchain and figure out how much they stole.

\subsection{Churn rate analysis}
\label{sec:churn}
We determined the churn rates of two subsequent consensuses for all 69,133
consensuses that cover Oct 2007 to Aug 2015.  There are 158 gaps in the
archived data, so we ended up with $68,975 \cdot 2 = 137,950$ churn values for
both time series (for joining and leaving relays).
Figure~\ref{fig:churn-density} illustrates a density plot that shows the
distribution of all these churn values, 99.97\% of which are in the interval
$[0, 0.1]$.  The diagram further features 37 vertical dotted lines that mark
outliers above 0.1.  Table~\ref{tab:churn-dist} gives an overview of our time
series statistics.

\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{diagrams/churn-density.pdf}
	\caption{Density of all churn values for relays that joined and left.  For
	both time series, 37 churn rates over eight years exceeded 0.1.  The dotted
	vertical lines mark all outliers.}
	\label{fig:churn-density}
\end{figure}

\begin{table}[t]
	\centering
	\begin{tabular}{ccccccc}
	\textbf{Churn type} & \textbf{Min.} & \textbf{Median} & \textbf{Mean} & \textbf{Max.} \\
	\hline
	New & 0.000 & 0.026 & 0.029 & 0.319 \\
	Gone & 0.003 & 0.025 & 0.029 & 0.412 \\
	\end{tabular}
	\caption{Summary of the distribution of churn rates for all consensuses
	since 2007.}
	\label{tab:churn-dist}
\end{table}

Figure~\ref{fig:2008-08} illustrates the churn rates for Aug 2008, featuring
our biggest anomaly.  On Aug 19, 822 relays left the network, resulting in a
sudden spike of the churn rate, and a trend increase in the time series.  The
spike was caused by the switch from consensus method three to four, which
happened on Aug 19, 2008.  The changelog says that in consensus method four,
routers that do not have the \texttt{Running} flag are no longer listed in the
consensus.

\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{diagrams/2008-08.pdf}
	\caption{On Aug 19, 822 relays suddenly left the Tor network, resulting in a
	churn rate spike, and an increase in the base rate of the time series.  The
	event was caused by the switch from consensus method three to four,
	basically an upgrade of the Tor network's consensus format.}
	\label{fig:2008-08}
\end{figure}

To alleviate the choice of a detection threshold, we plot the number of alerts
(in log scale) as the threshold increases.  We calculate these numbers for four
window sizes for the simple moving average.  The results are shown in
Figure~\ref{fig:threshold-alarm}.  Note that the number of alerts is for eight
years.  For comparison, the dashed black line represents the number of alerts
raised by The Tor Project's detection script.  Depending on the window size,
thresholds above 0.055 seem reasonable considering that 200 alerts average to
approximately one alert in two weeks---a tolerable number of incidents to
investigate.  Unfortunately, we are unable to determine the false positive rate
because we do not have ground truth.

\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{diagrams/threshold-alarm.pdf}
	\caption{The number of alerts (in log scale) as the detection threshold
	increases.  We used four window sizes for the simple moving average.  For
	comparison, the dashed black line at y=47 represents the number of alerts
	raised by The Tor Project's script.}
	\label{fig:threshold-alarm}
\end{figure}

\subsection{Uptime analysis}
\label{sec:uptime}
We generated relay uptime illustrations for every month since 2007, resulting in
93 uptime visualizations.  We now discuss a subset of these images that contain
particularly interesting patterns.

Figure~\ref{fig:2010-06-planetlab} shows Jun 2010, featuring a clear ``Sybil
block'' on the left side.  The Sybils belonged to a researcher who, as
documented by The Tor Project~\cite{progressreport}, started 512 Tor relays on
PlanetLab for research on scalability.  Our manual analysis could verify this.
The relays were easy to identify because their nicknames suggested that they
were hosted on PlanetLab, containing strings such as ``planetlab,'' ``planet,''
and ``plab.''  Note the small height of the Sybil block, indicating that the
relays were not online for a long time.

\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{diagrams/2010-06.jpg}
	\caption{In Jun 2010, a researcher started 512 Tor relays on PlanetLab for,
		as The Tor Project documented, ``their research into cloud computing and
		scaling effects''~\cite{progressreport}.  As illustrated by the easily
		visible red bar on the left, the relays were only online for a short
		while.}
	\label{fig:2010-06-planetlab}
\end{figure}

Figure~\ref{fig:2012-08-steppattern} features a curious ``step pattern'' for
approximately 100 relays, all of which were located in Russia and Germany.  The
relays appeared in Dec 2011, and started exhibiting the diurnal step
pattern (nine hours uptime followed by 15 hours downtime) in Mar 2012.  All
relays had similar nicknames, consisting of eight seemingly randomly-generated
characters.  In Apr 2013, the relays finally disappeared.

\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{diagrams/2012-08.jpg}
	\caption{Aug 2012 featured a curious ``step pattern,'' caused by
	approximately 100 Sybils.  Out of 24 hours, the relays were online for only
	nine hours.}
	\label{fig:2012-08-steppattern}
\end{figure}

Figure~\ref{fig:2014-04-heartbleed} shows the effect of the Heartbleed
incident~\cite{Durumeric2014a} on the Tor network.  Several days after the
incident, The Tor Project decided to block all relays that had not generated new
key pairs.  The large red block in the middle of the picture illustrates when
the biggest part of the block became active, rejecting approximately 1,700 Tor
relay fingerprints.
% $ wc -l dirauth-conf/approved-routers.d/bleeding-edges.conf
% 1779 dirauth-conf/approved-routers.d/bleeding-edges.conf

\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{diagrams/2014-04.jpg}
	\caption{Apr 2014, the month the Heartbleed bug was discovered.
		The large block in the middle of the diagram happened because The
		Tor Project eventually rejected a large number of relays that did not
		change their keypairs in time.}
		\label{fig:2014-04-heartbleed}
\end{figure}

Figure~\ref{fig:2014-12-lizard} illustrates the largest Sybil group to date,
comprising 3,347 Tor relays that an attacker started in the Google cloud in
Dec 2014.  Because of its magnitude, the attack was spotted almost
instantly, and The Tor Project was quick to remove the offending relays nine
hours after the appeared.

\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{diagrams/2014-12.jpg}
	\caption{Dec 2014, when a group of attackers started several hundred Tor
	relays in the Google cloud.  The relays were only online for a small number
	of hours because they were promptly rejected by The Tor Project.}
	\label{fig:2014-12-lizard}
\end{figure}

\subsection{Fingerprint anomalies}
\label{sec:fingerprint-anomalies}
We determined how often all Tor relays changed their fingerprint from 2007 to
2015.  Figure~\ref{fig:fingerprints} illustrates the number of fingerprints
(y-axis) we have observed for the 1,000 Tor relays (x-axis) that changed their
fingerprint the most.  All these relays changed their fingerprint at least ten
times.  Twenty one relays changed their fingerprint more than 100 times, and the
relay at the very right end of the distribution changed its fingerprint 936
times.  This relay's nickname was ``openwrt,'' suggesting that it was a home
router that was rebooted regularly.  It was running from Aug 2010 to Dec 2010.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\linewidth]{diagrams/fingerprints.pdf}
	\caption{The number of observed fingerprints for the 1,000 relays that
	changed their fingerprints the most.  Note the curious plateau in the shaded
	area between index 707 and 803---a Sybil group that changed their
	fingerprint exactly 24 times, probably as part of an experiment for a
	S\&P'13 paper~\cite{Biryukov2013a}.}
	\label{fig:fingerprints}
\end{figure}

Figure~\ref{fig:fingerprints} further contains a peculiar plateau, shown in the
shaded area between index 707 and 803.  This plateau was caused by a group of
Sybils, hosted in Amazon EC2, that changed their fingerprint exactly 24 times.

We also found that many IP addresses in the range 199.254.238.0/24 changed their
fingerprint frequently.  We contacted the owner of the address block and were
told that the block used to host VPN services.  Apparently, several people
started Tor relays and since the VPN service would not assign permanent IP
addresses, the Tor relays would periodically change their address, causing the
churn we observe.

\subsection{Accuracy of nearest-neighbor search}
\label{sec:accuracy}
How good is our nearest-neighbor search at finding Sybils?  To answer this
question, we now evaluate our algorithm's \emph{accuracy}, which we define as
the fraction of neighbors it correctly labels as Sybils.  For example, if eight
out of ten Sybils are correctly labeled as neighbors, the accuracy is 0.8.

% We lack ground truth and a comprehensive data set.
A proper evaluation requires ground truth, i.e., relays that are \emph{known} to
be Sybils.  All we have, however, are relays that we \emph{believe} are Sybils.
More importantly, the Sybils we found are not exhaustive, meaning that there are
likely Sybil groups we did not detect.  Therefore, our evaluation is doomed to
overestimate our algorithm's accuracy because we are unable to test it on the
Sybils we did not discover.

% Our two evaluation datasets.
We evaluate our search algorithm on two datasets, the Sybil group that were
bad exit relays (see Table~\ref{tab:exitmap-dataset}), and relay families.  We
chose the bad exit Sybils because their identical active attacks give us
confidence that they are, in fact, Sybils.  A relay family is a set of Tor
relays that is controlled by one operator, and is configured to express this
mutual relationship in the family members' configuration file.  In a way, relay
families can be seen as benign Sybils.  Tor clients never use more than one
member of a family in their path to prevent correlation attacks.  As of Nov.
2015, there are approximately 350 families in the network whose size ranges from
only two to 20 relays.  We can evaluate our algorithm by making it find the
nearest neighbors of a family member, which, ideally, should be its family
members.  Again, using families as ground truth is very likely to overestimate
results because family operators frequently configure their relays almost
identically.  At the time of this writing, a popular relay family uses the
nicknames ``AccessNow000'' to ``AccessNow009,'' uses adjacent IP addresses, and
identical contact information.  We expect the operators of malicious Sybils,
however, to go out of their way to obscure the relationship between their
relays.

% Concrete MyFamily experiment.
To determine our algorithm's accuracy, we used all relay families that were
present in the first consensus that was published in Oct. 2015.  For every relay
that had at least one mutual family relationship, we built a vantage point tree and then
searched for its $n$ nearest neighbors where $n$ is the amount of mutual family
relationships.  Basically, we evaluated how good our algorithm is at finding the
relatives of a family member.  For every relative in a family, we determined the
accuracy, a value in $[0,1]$.  The result, a distribution of accuracy values, is
shown in Figure~\ref{fig:family-accuracy}.

% Concrete bad exit experiment.
Next, we evaluate our algorithm with the bad exit Sybil groups from
Table~\ref{tab:exitmap-dataset}.  Similar to the previous evaluation, we build a
vantage point tree for every bad exit relay, and then use it to find its $n$
nearest neighbors where $n$ is the size of the Sybil group.  The accuracy is the
fraction of relays that we determined as neighbor.  The result is illustrated
in Figure~\ref{fig:badexit-accuracy}.

\begin{figure}
\centering
\subfigure[Bad exit relay Sybils]{
	\includegraphics[width=0.46\linewidth]{diagrams/bad-relay-accuracy.pdf}
\label{fig:badexit-accuracy}
}
\subfigure[Benign family Sybils]{
	\includegraphics[width=0.46\linewidth]{diagrams/family-accuracy.pdf}
\label{fig:family-accuracy}
}
\caption{ECDF for our two evaluations, the bad exit Sybils
	in Fig.~\ref{fig:badexit-accuracy} and the benign family Sybils
	in Fig.~\ref{fig:family-accuracy}.}
\label{fig:accuracy}
\end{figure}

As expected, our algorithm is significantly more accurate for the family
dataset---66\% of searches had perfect accuracy.  The bad exit dataset, however,
did worse.  59\% of all searches had an accuracy in the interval $[0.3,0.6]$,
and not a single search had perfect accuracy.

\subsection{Computational cost}
\label{sec:performance}
We are interested in the computational cost of our analysis techniques.  Fast
methods lend themselves to being run hourly, for every new consensus, while
slower techniques must be run less frequent.  Table~\ref{tab:exp-deployment}
gives an overview of the runtime of our methods.\footnote{We determined all
performance numbers on an Intel Core i7-3520M CPU at 2.9 GHz, a consumer-grade
CPU.}  Note that we placed our datasets on a solid state drive, to shift
eliminate I/O as performance bottleneck.

\begin{table}[t]
	\small
	\centering
	\begin{tabular}{lccc}
	\textbf{Method} & \textbf{Invocation} & \textbf{Analysis window} & \textbf{Run time} \\
	\hline
	Network churn & Hourly & Two consensuses & $\sim$0.16s \\
	Nearest-neighbor & Daily & One consensus & $\sim$15s \\
	Fingerprint & Daily & One month & $\sim$55s \\
	Uptime matrix & Daily & One month & $\sim$67s \\
	%Similarity matrix & Daily & One consensus & $\sim$26s \\
	\end{tabular}
	\caption{The computational cost of our analysis techniques, measured in
	execution time.  Network churn analysis is very fast and can easily be run
	hourly while the creation of a similarity matrix takes more time and can be
	run daily.}
	\label{tab:exp-deployment}
\end{table}

The table columns contain, from left to right, our analysis technique, how often
we intend to run the technique, the technique's data time window, and how long
it takes to compute its output.  The calculation of network churn is very
fast---it takes as input only two consensus files---and can easily be done for
every network consensus.  Nearest-neighbor search takes approximately 15
seconds, most of which is spent building the vantage point tree.  We used
nearest-neighbor search for manual analysis, but it can also be used
automatically.  Fingerprint and uptime analysis for one month work of consensus
files both take approximately one minute and can easily be run daily.  Finally,
the creation of the similarity matrix is prohibitively slow for all currently
running 7,000 relays because of its quadratic runtime, but it can be created for
a subset of 1,882 relays in approximately 26 seconds.
